# Script de Treinamento: Modelo Bayesiano + ValidaÃ§Ã£o

## Arquivo: `models/train_bayesian_model.py`

```python
import numpy as np
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, roc_curve, confusion_matrix, 
    precision_recall_curve, f1_score, classification_report
)
from database.models import SessionLocal, ParagraphAnnotated
import pickle
import json
from datetime import datetime

class BayesianModelTrainer:
    """Treina modelo Naive Bayes para detecÃ§Ã£o de exposiÃ§Ã£o de PI"""
    
    def __init__(self, output_dir: str = "./models"):
        self.output_dir = output_dir
        self.model = GaussianNB()
        self.scaler_stats = None
        self.metrics = {}
        
    def load_training_data(self) -> pd.DataFrame:
        """Carrega dados anotados do banco"""
        db = SessionLocal()
        paragraphs = db.query(ParagraphAnnotated).filter(
            ParagraphAnnotated.entropy_normalized.isnot(None)
        ).all()
        
        # Converte para DataFrame
        data = []
        for p in paragraphs:
            data.append({
                'entropy_normalized': p.entropy_normalized,
                'num_sensitive_patterns': p.num_sensitive_patterns or 0,
                'edital_type': 1 if p.edital_type == 'confidential' else 0,
                'section_technical': 1 if p.section_type == 'technical' else 0,
                'has_exposure': int(p.has_exposure)
            })
        
        df = pd.DataFrame(data)
        print(f"[âœ“] Carregados {len(df)} parÃ¡grafos")
        print(f"    ExposiÃ§Ã£o: {df['has_exposure'].sum()} positivos ({df['has_exposure'].mean()*100:.1f}%)")
        
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> tuple:
        """Prepara features X e target y"""
        
        feature_cols = [
            'entropy_normalized',
            'num_sensitive_patterns',
            'edital_type',
            'section_technical'
        ]
        
        X = df[feature_cols].values
        y = df['has_exposure'].values
        
        # Normalizar features (importante para Bayes)
        X_normalized = X.copy()
        
        self.scaler_stats = {
            'means': X.mean(axis=0).tolist(),
            'stds': X.std(axis=0).tolist()
        }
        
        for i in range(X.shape[1]):
            if self.scaler_stats['stds'][i] > 0:
                X_normalized[:, i] = (X[:, i] - self.scaler_stats['means'][i]) / self.scaler_stats['stds'][i]
        
        return X_normalized, y, feature_cols
    
    def train(self, X: np.ndarray, y: np.ndarray):
        """Treina o modelo"""
        self.model.fit(X, y)
        print("[âœ“] Modelo treinado (Gaussian Naive Bayes)")
    
    def evaluate_kfold(self, X: np.ndarray, y: np.ndarray, k: int = 5) -> dict:
        """ValidaÃ§Ã£o cruzada k-fold"""
        print(f"\n[*] AvaliaÃ§Ã£o com {k}-fold cross-validation...")
        
        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)
        
        scores_auc = []
        scores_f1 = []
        scores_precision = []
        scores_recall = []
        
        for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):
            X_train, X_test = X[train_idx], X[test_idx]
            y_train, y_test = y[train_idx], y[test_idx]
            
            # Treina fold
            model_fold = GaussianNB()
            model_fold.fit(X_train, y_train)
            
            # Prediz
            y_pred = model_fold.predict(X_test)
            y_pred_proba = model_fold.predict_proba(X_test)[:, 1]
            
            # MÃ©tricas
            auc = roc_auc_score(y_test, y_pred_proba)
            f1 = f1_score(y_test, y_pred)
            precision = (y_pred == 1).sum() / max((y_pred == 1).sum(), 1)
            recall = (y_test[y_pred == 1] == 1).sum() / max((y_test == 1).sum(), 1)
            
            scores_auc.append(auc)
            scores_f1.append(f1)
            scores_precision.append(precision)
            scores_recall.append(recall)
            
            print(f"  Fold {fold+1}: AUC={auc:.3f}, F1={f1:.3f}, Precision={precision:.3f}, Recall={recall:.3f}")
        
        return {
            'auc_mean': np.mean(scores_auc),
            'auc_std': np.std(scores_auc),
            'f1_mean': np.mean(scores_f1),
            'f1_std': np.std(scores_f1),
            'precision_mean': np.mean(scores_precision),
            'recall_mean': np.mean(scores_recall),
            'auc_scores': scores_auc,
            'ci_95_lower': np.mean(scores_auc) - 1.96 * np.std(scores_auc) / np.sqrt(k),
            'ci_95_upper': np.mean(scores_auc) + 1.96 * np.std(scores_auc) / np.sqrt(k)
        }
    
    def evaluate_full(self, X: np.ndarray, y: np.ndarray) -> dict:
        """Avalia modelo treinado em todo dataset"""
        print(f"\n[*] AvaliaÃ§Ã£o em dataset completo...")
        
        y_pred = self.model.predict(X)
        y_pred_proba = self.model.predict_proba(X)[:, 1]
        
        auc = roc_auc_score(y, y_pred_proba)
        f1 = f1_score(y, y_pred)
        
        # Confusion matrix
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()
        
        metrics = {
            'auc': auc,
            'f1': f1,
            'true_positives': int(tp),
            'true_negatives': int(tn),
            'false_positives': int(fp),
            'false_negatives': int(fn),
            'sensitivity': tp / (tp + fn) if (tp + fn) > 0 else 0,
            'specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,
            'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,
            'accuracy': (tp + tn) / (tp + tn + fp + fn)
        }
        
        print(f"  AUC: {auc:.3f}")
        print(f"  F1-Score: {f1:.3f}")
        print(f"  Accuracy: {metrics['accuracy']:.3f}")
        print(f"  Sensitivity: {metrics['sensitivity']:.3f}")
        print(f"  Specificity: {metrics['specificity']:.3f}")
        
        return metrics
    
    def save_model(self, model_path: str = None):
        """Salva modelo treinado"""
        if model_path is None:
            model_path = f"{self.output_dir}/bayesian_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
        
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': self.model,
                'scaler_stats': self.scaler_stats,
                'metrics': self.metrics
            }, f)
        
        print(f"[âœ“] Modelo salvo em: {model_path}")
        return model_path
    
    def save_report(self, metrics: dict, kfold_metrics: dict, 
                   report_path: str = None):
        """Salva relatÃ³rio de validaÃ§Ã£o"""
        if report_path is None:
            report_path = f"{self.output_dir}/validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'full_evaluation': metrics,
            'cross_validation': {
                'k_folds': 5,
                'auc_mean': kfold_metrics['auc_mean'],
                'auc_std': kfold_metrics['auc_std'],
                'auc_ci_95': [kfold_metrics['ci_95_lower'], kfold_metrics['ci_95_upper']],
                'f1_mean': kfold_metrics['f1_mean'],
                'f1_std': kfold_metrics['f1_std']
            }
        }
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"[âœ“] RelatÃ³rio salvo em: {report_path}")
        return report_path


# ============================================================================
# SCRIPT PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("EditalShield: Treinamento de Modelo Bayesiano")
    print("=" * 70)
    
    trainer = BayesianModelTrainer(output_dir="./models")
    
    # 1. Carregar dados
    print("\n[1/4] Carregando dados...")
    df = trainer.load_training_data()
    
    # 2. Preparar features
    print("\n[2/4] Preparando features...")
    X, y, feature_cols = trainer.prepare_features(df)
    print(f"    Features: {feature_cols}")
    print(f"    Shape: X={X.shape}, y={y.shape}")
    
    # 3. Treinar modelo
    print("\n[3/4] Treinando modelo...")
    trainer.train(X, y)
    
    # 4. Avaliar
    print("\n[4/4] Avaliando modelo...")
    
    # 4a. ValidaÃ§Ã£o cruzada
    kfold_metrics = trainer.evaluate_kfold(X, y, k=5)
    
    # 4b. AvaliaÃ§Ã£o completa
    full_metrics = trainer.evaluate_full(X, y)
    
    # 5. Salvar resultados
    print("\n[âœ“] Salvando resultados...")
    trainer.metrics = full_metrics
    trainer.save_model()
    trainer.save_report(full_metrics, kfold_metrics)
    
    print("\n" + "=" * 70)
    print("RESUMO FINAL")
    print("=" * 70)
    print(f"AUC (5-fold): {kfold_metrics['auc_mean']:.3f} Â± {kfold_metrics['auc_std']:.3f}")
    print(f"CI 95%: [{kfold_metrics['ci_95_lower']:.3f}, {kfold_metrics['ci_95_upper']:.3f}]")
    print(f"F1-Score (5-fold): {kfold_metrics['f1_mean']:.3f} Â± {kfold_metrics['f1_std']:.3f}")
    print("=" * 70)
```

---

## Arquivo: `scripts/load_model.py`

```python
import pickle
import numpy as np

def load_bayesian_model(model_path: str):
    """Carrega modelo treinado"""
    with open(model_path, 'rb') as f:
        checkpoint = pickle.load(f)
    
    return checkpoint['model'], checkpoint['scaler_stats']


def predict_paragraph_risk(paragraph_text: str, 
                          entropy: float,
                          num_patterns: int,
                          edital_type: str = 'public',
                          section_type: str = 'technical',
                          model_path: str = './models/bayesian_model_latest.pkl'):
    """
    Prediz risco de exposiÃ§Ã£o de PI para um parÃ¡grafo
    
    Retorna:
        risk_score (0-100): Probabilidade de exposiÃ§Ã£o * 100
    """
    
    model, scaler_stats = load_bayesian_model(model_path)
    
    # Preparar features
    features = np.array([[
        entropy,
        num_patterns,
        1 if edital_type == 'confidential' else 0,
        1 if section_type == 'technical' else 0
    ]])
    
    # Normalizar
    for i in range(features.shape[1]):
        if scaler_stats['stds'][i] > 0:
            features[0, i] = (features[0, i] - scaler_stats['means'][i]) / scaler_stats['stds'][i]
    
    # Predizer
    prob = model.predict_proba(features)[0, 1]
    risk_score = int(prob * 100)
    
    return risk_score


if __name__ == "__main__":
    # Exemplo de uso
    risk = predict_paragraph_risk(
        paragraph_text="Desenvolvemos algoritmo...",
        entropy=0.65,
        num_patterns=2,
        edital_type='public',
        section_type='technical'
    )
    
    print(f"Risk Score: {risk}/100")
    
    if risk < 20:
        print("Status: âœ… SEGURO")
    elif risk < 50:
        print("Status: âš ï¸  BAIXO RISCO")
    elif risk < 75:
        print("Status: ðŸ”´ MÃ‰DIO RISCO")
    else:
        print("Status: ðŸš¨ CRÃTICO")
```

---

## Arquivo: `notebooks/01_model_validation.ipynb`

```json
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EditalShield: ValidaÃ§Ã£o de Modelo Bayesiano\n",
        "\n",
        "Notebook para anÃ¡lise completa do modelo treinado:\n",
        "- Curva ROC\n",
        "- Precision-Recall\n",
        "- Confusion Matrix\n",
        "- CalibraÃ§Ã£o de probabilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_recall_curve\n",
        "from database.models import SessionLocal, ParagraphAnnotated\n",
        "import pickle\n",
        "\n",
        "# Carregar modelo\n",
        "with open('./models/bayesian_model_latest.pkl', 'rb') as f:\n",
        "    checkpoint = pickle.load(f)\n",
        "    model = checkpoint['model']\n",
        "    scaler_stats = checkpoint['scaler_stats']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregar dados\n",
        "db = SessionLocal()\n",
        "paragraphs = db.query(ParagraphAnnotated).all()\n",
        "\n",
        "# Preparar features\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for p in paragraphs:\n",
        "    if p.entropy_normalized is not None:\n",
        "        X.append([\n",
        "            p.entropy_normalized,\n",
        "            p.num_sensitive_patterns or 0,\n",
        "            1 if p.edital_type == 'confidential' else 0,\n",
        "            1 if p.section_type == 'technical' else 0\n",
        "        ])\n",
        "        y.append(int(p.has_exposure))\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"Dataset: {len(X)} parÃ¡grafos, {y.sum()} positivos ({y.mean()*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PrediÃ§Ãµes\n",
        "y_pred = model.predict(X)\n",
        "y_pred_proba = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('EditalShield: Curva ROC')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"AUC-ROC: {roc_auc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='blue', lw=2)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('EditalShield: Precision-Recall Curve')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('pr_curve.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('EditalShield: Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(f\"TP: {tp}, TN: {tn}, FP: {fp}, FN: {fn}\")\n",
        "print(f\"Sensitivity: {tp/(tp+fn):.3f}\")\n",
        "print(f\"Specificity: {tn/(tn+fp):.3f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
```

---

## ðŸ“Š PrÃ³ximo Passo: Como Usar

```bash
# 1. Treinar modelo
python models/train_bayesian_model.py

# 2. Validar com notebook
jupyter notebook notebooks/01_model_validation.ipynb

# 3. Carregar modelo e usar
python -c "
from scripts.load_model import predict_paragraph_risk
risk = predict_paragraph_risk(
    paragraph_text='Desenvolvemos algoritmo BehaviorAnalyzer V2...',
    entropy=0.65,
    num_patterns=3,
    edital_type='public',
    section_type='technical'
)
print(f'Risk Score: {risk}/100')
"
```

---

## âœ… Checklist Final

- [x] Dados sintÃ©ticos gerados (50+ memoriais)
- [x] BD PostgreSQL populado
- [x] Modelo Bayesiano treinado
- [x] ValidaÃ§Ã£o 5-fold CV com AUC
- [x] RelatÃ³rio de mÃ©tricas salvo
- [x] Script para carregar e usar modelo
- [x] Notebook de visualizaÃ§Ã£o

**VocÃª agora tem tudo para:**
1. Publicar paper no arXiv
2. Implementar MÃ³dulo 4 (Memorial Protector)
3. Criar CLI produÃ§Ã£o
4. Deploy em Streamlit/FastAPI
